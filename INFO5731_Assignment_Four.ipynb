{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jivitheshreddy/INFO-5731-Srping2023/blob/main/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "4ebe4726-c4e3-4ff1-8762-64a5e1d68369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0  whether orgies showcasing various bodily fluid...          1\n",
              "1  so many reviews praise film level debauchery s...          1\n",
              "2  this film felt like written directed high scho...          1\n",
              "3  in opening scene babylon elephant pickup empti...          0\n",
              "4  after interesting opening scene main character...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab7fa299-c025-4de8-a353-63ffa811b601\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>whether orgies showcasing various bodily fluid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many reviews praise film level debauchery s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this film felt like written directed high scho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in opening scene babylon elephant pickup empti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>after interesting opening scene main character...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab7fa299-c025-4de8-a353-63ffa811b601')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab7fa299-c025-4de8-a353-63ffa811b601 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab7fa299-c025-4de8-a353-63ffa811b601');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "df=pd.read_csv('Reviews_Sentiment.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim import corpora, models\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Preprocess text data\n",
        "stop_words = stopwords.words('english')\n",
        "df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in stop_words]))\n",
        "df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.lower().split() if word.isalpha()]))\n",
        "\n",
        "# Create dictionary and bag-of-words representation\n",
        "texts = df['Review'].apply(lambda x: x.split())\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Train LDA model\n",
        "num_topics = 10\n",
        "lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
        "\n",
        "# Print top topics\n",
        "for i, topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
        "    print(f\"Topic {i+1}: {topic}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px6JCVYRJWIS",
        "outputId": "0f78e7a6-32a0-43c4-ffed-8ab864bcdf4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: 0.015*\"film\" + 0.011*\"party\" + 0.009*\"characters\" + 0.008*\"movie\" + 0.007*\"one\" + 0.007*\"also\" + 0.007*\"chazelle\" + 0.006*\"sequence\" + 0.006*\"helpful\" + 0.006*\"films\"\n",
            "Topic 2: 0.023*\"movie\" + 0.017*\"helpful\" + 0.013*\"character\" + 0.011*\"hollywood\" + 0.011*\"like\" + 0.009*\"film\" + 0.009*\"review\" + 0.009*\"permalink\" + 0.008*\"dont\" + 0.008*\"sign\"\n",
            "Topic 3: 0.022*\"movie\" + 0.015*\"film\" + 0.013*\"babylon\" + 0.013*\"hollywood\" + 0.011*\"helpful\" + 0.009*\"chazelle\" + 0.009*\"wants\" + 0.008*\"la\" + 0.007*\"also\" + 0.007*\"dont\"\n",
            "Topic 4: 0.021*\"movie\" + 0.020*\"babylon\" + 0.011*\"helpful\" + 0.010*\"hollywood\" + 0.009*\"people\" + 0.008*\"like\" + 0.008*\"characters\" + 0.008*\"pretty\" + 0.007*\"film\" + 0.007*\"time\"\n",
            "Topic 5: 0.032*\"films\" + 0.023*\"given\" + 0.014*\"babylon\" + 0.014*\"even\" + 0.014*\"would\" + 0.014*\"chazelles\" + 0.010*\"film\" + 0.009*\"la\" + 0.009*\"chazelle\" + 0.009*\"helpful\"\n",
            "Topic 6: 0.090*\"film\" + 0.049*\"times\" + 0.039*\"busy\" + 0.021*\"much\" + 0.021*\"helpful\" + 0.020*\"characters\" + 0.020*\"get\" + 0.020*\"would\" + 0.020*\"hate\" + 0.020*\"enjoyed\"\n",
            "Topic 7: 0.025*\"babylon\" + 0.010*\"film\" + 0.010*\"helpful\" + 0.010*\"scene\" + 0.010*\"hollywood\" + 0.010*\"love\" + 0.010*\"movies\" + 0.008*\"chazelle\" + 0.008*\"films\" + 0.008*\"much\"\n",
            "Topic 8: 0.023*\"like\" + 0.019*\"helpful\" + 0.019*\"hollywood\" + 0.019*\"people\" + 0.015*\"movie\" + 0.014*\"made\" + 0.014*\"anyone\" + 0.013*\"actual\" + 0.010*\"audience\" + 0.010*\"well\"\n",
            "Topic 9: 0.049*\"film\" + 0.013*\"helpful\" + 0.013*\"la\" + 0.011*\"movie\" + 0.011*\"really\" + 0.009*\"like\" + 0.009*\"first\" + 0.009*\"films\" + 0.009*\"felt\" + 0.009*\"runtime\"\n",
            "Topic 10: 0.036*\"quite\" + 0.026*\"helpful\" + 0.020*\"film\" + 0.013*\"found\" + 0.013*\"sign\" + 0.013*\"vote\" + 0.013*\"review\" + 0.013*\"many\" + 0.013*\"permalink\" + 0.012*\"even\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "1213cef7-e428-4335-a7fe-df1083fd4df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Cross-validation scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Logistic Regression Mean CV accuracy: 1.0\n",
            "Logistic Regression Performance Metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Naive Bayes Cross-validation scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Naive Bayes Mean CV accuracy: 1.0\n",
            "Naive Bayes Performance Metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/Reviews_Sentiment.csv')\n",
        "\n",
        "# Split the data into training and testing sets (80% for training and 20% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Use CountVectorizer to create a bag-of-words representation of the text\n",
        "# Use TfidfVectorizer to create a TF-IDF representation of the text\n",
        "vectorizer = CountVectorizer(stop_words='english') # or TfidfVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Use Logistic Regression algorithm to build the sentiment classifier\n",
        "lr = LogisticRegression(random_state=42)\n",
        "scores = cross_val_score(lr, X_train_vec, y_train, cv=10)\n",
        "print(f\"Logistic Regression Cross-validation scores: {scores}\")\n",
        "print(f\"Logistic Regression Mean CV accuracy: {scores.mean()}\")\n",
        "\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred_lr = lr.predict(X_test_vec)\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_lr)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_lr)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_lr)}\")\n",
        "\n",
        "# Use Naive Bayes algorithm to build the sentiment classifier\n",
        "nb = MultinomialNB()\n",
        "scores = cross_val_score(nb, X_train_vec, y_train, cv=10)\n",
        "print(f\"Naive Bayes Cross-validation scores: {scores}\")\n",
        "print(f\"Naive Bayes Mean CV accuracy: {scores.mean()}\")\n",
        "\n",
        "nb.fit(X_train_vec, y_train)\n",
        "y_pred_nb = nb.predict(X_test_vec)\n",
        "\n",
        "print(\"Naive Bayes Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_nb)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_nb)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_nb)}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "train_data = train_data.select_dtypes(include=['number']).interpolate().dropna()\n",
        "test_data = test_data.select_dtypes(include=['number']).interpolate().dropna()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train = train_data.drop(['SalePrice','Id'], axis=1)\n",
        "y_train = np.log(train_data.SalePrice)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=21, test_size=0.2)\n",
        "\n",
        "# Create a linear regression model and fit it to the training data\n",
        "regression = LinearRegression()\n",
        "regression.fit(X_train, y_train)\n",
        "\n",
        "# Predict the house prices on the test set\n",
        "y_pred = regression.predict(X_test)\n",
        "\n",
        "# Evaluate the model using R squared and root mean squared error (RMSE)\n",
        "print('Linear Regression R squared: %.4f' % regression.score(X_test, y_test))\n",
        "rmse = np.sqrt(mean_squared_error(np.exp(y_pred), np.exp(y_test)))\n",
        "print('Root Mean Squared Error: %.4f' % rmse)\n",
        "\n",
        "# Create a dataframe to compare the predicted and actual house prices and calculate the percentage difference\n",
        "results = {\"Predicted Prices\": np.exp(y_pred), \"Actual Prices\": np.exp(y_test)}\n",
        "df_val = pd.DataFrame(results)\n",
        "df_val[\"Percentage Difference\"] = round(abs((df_val[\"Predicted Prices\"] - df_val[\"Actual Prices\"]) / df_val[\"Actual Prices\"]) * 100, 2)\n",
        "df_val\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "QNPbtzMsNbuc",
        "outputId": "c1751a0b-f93b-44ef-eb0c-c1c08053fe0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression R squared: 0.8493\n",
            "Root Mean Squared Error: 44631.2449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Predicted Prices  Actual Prices  Percentage Difference\n",
              "880      156677.762126       157000.0                   0.21\n",
              "605      229973.921577       205000.0                  12.18\n",
              "1166     245358.948864       245350.0                   0.00\n",
              "216      218109.586021       210000.0                   3.86\n",
              "970       86909.329260       135000.0                  35.62\n",
              "...                ...            ...                    ...\n",
              "218      231419.797074       311500.0                  25.71\n",
              "1228     311321.804719       367294.0                  15.24\n",
              "1007      93234.996099        88000.0                   5.95\n",
              "575      109041.447359       118500.0                   7.98\n",
              "599      172431.414374       151000.0                  14.19\n",
              "\n",
              "[292 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e45e05e7-c3d6-480c-b482-ff82df7e1fc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Prices</th>\n",
              "      <th>Actual Prices</th>\n",
              "      <th>Percentage Difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>156677.762126</td>\n",
              "      <td>157000.0</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>229973.921577</td>\n",
              "      <td>205000.0</td>\n",
              "      <td>12.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1166</th>\n",
              "      <td>245358.948864</td>\n",
              "      <td>245350.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>218109.586021</td>\n",
              "      <td>210000.0</td>\n",
              "      <td>3.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>86909.329260</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>35.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>231419.797074</td>\n",
              "      <td>311500.0</td>\n",
              "      <td>25.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228</th>\n",
              "      <td>311321.804719</td>\n",
              "      <td>367294.0</td>\n",
              "      <td>15.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>93234.996099</td>\n",
              "      <td>88000.0</td>\n",
              "      <td>5.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>109041.447359</td>\n",
              "      <td>118500.0</td>\n",
              "      <td>7.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>172431.414374</td>\n",
              "      <td>151000.0</td>\n",
              "      <td>14.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>292 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e45e05e7-c3d6-480c-b482-ff82df7e1fc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e45e05e7-c3d6-480c-b482-ff82df7e1fc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e45e05e7-c3d6-480c-b482-ff82df7e1fc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pG0wdgs5PNaA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}